import time
import google.generativeai as genai

# ğŸ”¥ **TOKEN ve RATE LIMIT YÃ¶netimi iÃ§in Global DeÄŸiÅŸkenler**
MAX_TOKENS = 500  # Her istekte en fazla 500 token Ã¼retilebilir
CONTEXT_WINDOW = 1000  # Toplam 1000 tokenlÄ±k bir pencere var
WARNING_THRESHOLD = 0.8  # %80 dolduÄŸunda uyarÄ± ver

# ğŸ“Œ **Gemini Modelini BaÅŸlat**


def count_tokens(text, model):
    """Google Gemini API kullanarak metindeki token sayÄ±sÄ±nÄ± hesaplar."""
    response = model.count_tokens(text)
    return response.total_tokens  # GerÃ§ek token sayÄ±sÄ± dÃ¶ndÃ¼rÃ¼lÃ¼r

def get_token_usage(prompt, response_text, model):
    """Girilen metnin ve model yanÄ±tÄ±nÄ±n token kullanÄ±mÄ±nÄ± hesaplar."""
    input_tokens = count_tokens(prompt, model)
    output_tokens = count_tokens(response_text,model)
    total_tokens = input_tokens + output_tokens
    return input_tokens, output_tokens, total_tokens


# ğŸ“Œ **API Talebi Ä°Ã§in Otomatik Retry (Rate Limit HatasÄ±na KarÅŸÄ±)**
def api_request_with_retry(request_func, *args, **kwargs):
    retries = 1
    max_retries = 3
    api_error_shown = False  # API hatasÄ± mesajÄ±nÄ± sadece bir kez yazdÄ±rmak iÃ§in

    while retries <= max_retries:
        try:
            return request_func(*args, **kwargs)
        except Exception as e:
            error_message = str(e).lower()

            if "429" in error_message:  # Rate Limit HatasÄ±
                if not api_error_shown:
                    print(f"âš  API Rate Limit HatasÄ±: {e}")
                    api_error_shown = True

                wait_time = 2 ** retries  # Exponential backoff
                print(f"â³ API sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±! {wait_time} saniye bekleniyor... ({retries}/{max_retries})")
                time.sleep(wait_time)
                retries += 1
            else:
                print(f"âŒ API HatasÄ±: {e}")
                return None

    print("âŒ Maksimum tekrar sayÄ±sÄ±na ulaÅŸÄ±ldÄ±, API isteÄŸi baÅŸarÄ±sÄ±z oldu.")
    return None

def calculate_gemini_cost(input_tokens, output_tokens):
    """
    Gemini API kullanÄ±mÄ±nÄ±n tahmini maliyetini hesaplar.
    
    Pricing model (Per 1 Million Tokens):
    - Input:
        * Up to 128k tokens: $0.075 / 1M tokens
        * More than 128k tokens: $0.15 / 1M tokens
    - Output:   
        * Up to 128k tokens: $0.30 / 1M tokens
        * More than 128k tokens: $0.60 / 1M tokens
        
    Args:
        input_tokens (int): GiriÅŸ token sayÄ±sÄ±
        output_tokens (int): Ã‡Ä±kÄ±ÅŸ token sayÄ±sÄ±
        
    Returns:
        float: Toplam maliyet (USD)
    """
    # Calculate the cost of input tokens:
    if input_tokens <= 128_000:
        input_cost = (input_tokens / 1_000_000) * 0.075
    else:
        input_cost = (input_tokens / 1_000_000) * 0.15

    # Calculate the output cost:
    if output_tokens <= 128_000:
        output_cost = (output_tokens / 1_000_000) * 0.30
    else:
        output_cost = (output_tokens / 1_000_000) * 0.60

    return input_cost + output_cost